{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JBPskR0TNpIn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model loading"
      ],
      "metadata": {
        "id": "3hac5eUTPth6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedAutoEncoder(nn.Module):\n",
        "    def __init__(self, in_dim=9, maskable_dim=4, embed_dim=64, depth=4):\n",
        "        super().__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.maskable_dim = maskable_dim\n",
        "\n",
        "        self.mask_token = nn.Parameter(torch.zeros(in_dim))\n",
        "\n",
        "        layers = []\n",
        "        for _ in range(depth):\n",
        "            layers += [\n",
        "                nn.Linear(embed_dim if layers else in_dim, embed_dim),\n",
        "                nn.GELU(),\n",
        "                nn.LayerNorm(embed_dim)\n",
        "            ]\n",
        "        self.encoder = nn.Sequential(*layers)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(embed_dim, in_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = torch.where(mask, x, self.mask_token)\n",
        "        z = self.encoder(x)\n",
        "        return self.decoder(z)"
      ],
      "metadata": {
        "id": "-gqOAQ0OPP1w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = 'models/model.pt'"
      ],
      "metadata": {
        "id": "bLNnAyPDNxH7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(MODEL_PATH):\n",
        "    print(f\"Loading model from {MODEL_PATH}\")\n",
        "    model = MaskedAutoEncoder(in_dim=9, embed_dim=128).cuda()\n",
        "    model.load_state_dict(torch.load(MODEL_PATH))\n",
        "    model.eval()\n",
        "else:\n",
        "    print(f\"MAE model not found!\")"
      ],
      "metadata": {
        "id": "QY-h_ASzO5lr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204ada52-5f51-4015-9834-e0f9a9246376"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from models/model.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading"
      ],
      "metadata": {
        "id": "VIZ3-V12PwLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet(\"data/processed/nitrate_00_train_data.parquet\")\n",
        "cols = [\"temperature_00\", \"salinity_00\", \"oxygen_00\", \"phosphate_00\"]\n",
        "\n",
        "def encode_geospatial_features(df: pd.DataFrame) -> np.ndarray:\n",
        "    lat_rad = np.radians(df[\"lat\"].to_numpy())\n",
        "    lon_rad = np.radians(df[\"lon\"].to_numpy())\n",
        "\n",
        "    sin_lat = np.sin(lat_rad)\n",
        "    cos_lat = np.cos(lat_rad)\n",
        "    sin_lon = np.sin(lon_rad)\n",
        "    cos_lon = np.cos(lon_rad)\n",
        "\n",
        "    depth = df[\"depth\"].to_numpy(dtype=np.float32)\n",
        "    norm_depth = (depth - depth.min()) / (depth.max() - depth.min())\n",
        "\n",
        "    geo_features = np.stack([sin_lat, cos_lat, sin_lon, cos_lon, norm_depth], axis=1)\n",
        "    return geo_features.astype(np.float32)\n",
        "\n",
        "class Scaler:\n",
        "    def __init__(self, mean: dict[str, float], std: dict[str, float]):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.cols = list(mean.keys())\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, df, cols):\n",
        "        mean = {col: df[col].mean() for col in cols}\n",
        "        std = {col: df[col].std() for col in cols}\n",
        "        return cls(mean, std)\n",
        "\n",
        "    def normalize(self, tensor: torch.Tensor, cols: list[str]) -> torch.Tensor:\n",
        "        for i, col in enumerate(cols):\n",
        "            tensor[:, i] = (tensor[:, i] - self.mean[col]) / self.std[col]\n",
        "        return tensor\n",
        "\n",
        "    def denormalize(self, tensor: torch.Tensor, cols: list[str]) -> torch.Tensor:\n",
        "        means = torch.tensor([self.mean[c] for c in cols], dtype=tensor.dtype, device=tensor.device)\n",
        "        stds  = torch.tensor([self.std[c]  for c in cols], dtype=tensor.dtype, device=tensor.device)\n",
        "        return tensor * stds + means\n",
        "\n",
        "    def mae(self, reconstructed: torch.Tensor, ground_truth: torch.Tensor, cols: list[str]) -> float:\n",
        "        rec_denorm = self.denormalize(reconstructed.clone(), cols)\n",
        "        gt_denorm = self.denormalize(ground_truth.clone(), cols)\n",
        "        return torch.abs(rec_denorm - gt_denorm).mean().item()\n",
        "\n",
        "    def masked_mae(self, reconstructed: torch.Tensor, ground_truth: torch.Tensor, mask: torch.Tensor, cols: list[str]) -> float:\n",
        "        rec_denorm = self.denormalize(reconstructed.clone(), cols)\n",
        "        gt_denorm = self.denormalize(ground_truth.clone(), cols)\n",
        "\n",
        "        abs_error = torch.abs(rec_denorm - gt_denorm)\n",
        "        masked_error = abs_error * mask\n",
        "\n",
        "        mae = masked_error.sum() / mask.sum().clamp(min=1.0)\n",
        "        return mae.item()\n",
        "\n",
        "df = df.dropna(subset=cols).reset_index(drop=True)\n",
        "scaler = Scaler.from_dataframe(df, cols)\n",
        "geo = encode_geospatial_features(df)\n",
        "x = df[cols].to_numpy(dtype=np.float32)\n",
        "\n",
        "x_full = np.concatenate([x, geo], axis=1)\n",
        "\n",
        "X = torch.tensor(x_full)\n",
        "X = scaler.normalize(X.clone(), cols)\n",
        "\n",
        "class PredictionDataset(Dataset):\n",
        "    def __init__(self, X: torch.Tensor, y: torch.Tensor):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "TARGET         = \"nitrate_00\"\n",
        "TEST_BBOX      = {                       # Morze Śródziemne\n",
        "    \"lat_min\": 30.0, \"lat_max\": 46.0,\n",
        "    \"lon_min\": -6.0, \"lon_max\": 36.0\n",
        "}\n",
        "SEED           = 42\n",
        "N_JOBS         = -1\n",
        "SUB_FRAC       = 0.20\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "test_mask = (\n",
        "    (df[\"lat\"].between(TEST_BBOX[\"lat_min\"], TEST_BBOX[\"lat_max\"])) &\n",
        "    (df[\"lon\"].between(TEST_BBOX[\"lon_min\"], TEST_BBOX[\"lon_max\"]))\n",
        ")\n",
        "\n",
        "X_train_large = X[~test_mask, :].clone()\n",
        "X_test = X[test_mask, :].clone()\n",
        "\n",
        "y_train_large = df[~test_mask][TARGET].to_numpy(dtype=np.float32)\n",
        "y_test = df[test_mask][TARGET].to_numpy(dtype=np.float32)\n",
        "\n",
        "print(f\"X_train_large shape: {X_train_large.shape}\")\n",
        "print(f\"y_train_large  shape: {y_train_large.shape}\")\n",
        "\n",
        "idx = np.random.choice(X_train_large.shape[0], int((X_train_large.shape[0])*SUB_FRAC), replace=False)\n",
        "\n",
        "X_train = torch.Tensor(X_train_large[idx])\n",
        "y_train = torch.Tensor(y_train_large[idx])\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test  shape: {X_test.shape}\")\n",
        "\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test  shape: {y_test.shape}\")\n",
        "\n",
        "train_ds = PredictionDataset(X_train, y_train)\n",
        "test_ds  = PredictionDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=len(test_ds), shuffle=False)\n"
      ],
      "metadata": {
        "id": "YUOyThUAPzJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "782b7c08-adde-4577-a1ff-c1dd5f48cf9f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_large shape: torch.Size([601393, 9])\n",
            "y_train_large  shape: (601393,)\n",
            "X_train shape: torch.Size([120278, 9])\n",
            "X_test  shape: torch.Size([8519, 9])\n",
            "y_train shape: torch.Size([120278])\n",
            "y_test  shape: (8519,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop"
      ],
      "metadata": {
        "id": "Vm_m0WcKQS3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model_, loader_, n_epochs=20, lr=1e-3, weight_decay=1e-4, verbose=True, gradient_clipping=False):\n",
        "    opt = torch.optim.Adam(model_.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=n_epochs)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model_.train()\n",
        "        total_loss = 0\n",
        "        all_y = []\n",
        "        all_pred = []\n",
        "\n",
        "        for x, y in loader_:\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "            pred = model_(x).flatten()\n",
        "\n",
        "            loss = loss_fn(pred, y)\n",
        "            loss.backward()\n",
        "\n",
        "            if gradient_clipping:\n",
        "                torch.nn.utils.clip_grad_norm_(model_.parameters(), max_norm=1.0)\n",
        "\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            all_y.append(y.detach().cpu())\n",
        "            all_pred.append(pred.detach().cpu())\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Concatenate all predictions and targets\n",
        "        all_y = torch.cat(all_y).numpy()\n",
        "        all_pred = torch.cat(all_pred).numpy()\n",
        "\n",
        "        r2 = r2_score(all_y, all_pred)\n",
        "        avg_loss = total_loss / len(loader_)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch+1}: loss = {avg_loss:.4f}  R2 = {r2:.4f}\")\n",
        "\n",
        "    return avg_loss, r2\n",
        "\n",
        "def metrics(name, y, pred, verbose=True):\n",
        "    mse = mean_squared_error(y, pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae  = mean_absolute_error(y, pred)\n",
        "    r2   = r2_score(y, pred)\n",
        "    if verbose:\n",
        "        print(f\"{name:<18} RMSE={rmse:.4f} MSE={mse:.4f} MAE={mae:.4f} R2={r2:.4f}\")\n",
        "    return mse, rmse, mae, r2\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(name, model_, loader_):\n",
        "    model_.eval()\n",
        "    for x, y in loader_:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "        pred = model_(x).flatten()\n",
        "        y = y.detach().cpu().numpy()\n",
        "        pred = pred.detach().cpu().numpy()\n",
        "        return metrics(name, y, pred)\n",
        "\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)\n",
        "    elif isinstance(m, nn.LayerNorm):\n",
        "        nn.init.ones_(m.weight)\n",
        "        nn.init.zeros_(m.bias)"
      ],
      "metadata": {
        "id": "MCn5PEaHPk5j"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity check: linear prediction without embeddings"
      ],
      "metadata": {
        "id": "40sN9c2ifXB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineMLP(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super().__init__()\n",
        "        self.predictor = nn.Sequential(\n",
        "            nn.Linear(in_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.predictor(x).squeeze(-1)\n",
        "\n",
        "pred_model = BaselineMLP(in_dim=9).cuda()\n",
        "_ = train(pred_model, train_loader, n_epochs=20, lr=1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU-o-18-fb5d",
        "outputId": "c5ef6021-83b1-4a39-f6f3-a9fcb07ab228"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss = 60.4349  R2 = 0.6724\n",
            "Epoch 2: loss = 4.6641  R2 = 0.9747\n",
            "Epoch 3: loss = 4.0296  R2 = 0.9782\n",
            "Epoch 4: loss = 3.7618  R2 = 0.9796\n",
            "Epoch 5: loss = 3.6050  R2 = 0.9805\n",
            "Epoch 6: loss = 3.4932  R2 = 0.9811\n",
            "Epoch 7: loss = 3.4193  R2 = 0.9815\n",
            "Epoch 8: loss = 3.3547  R2 = 0.9818\n",
            "Epoch 9: loss = 3.3114  R2 = 0.9821\n",
            "Epoch 10: loss = 3.2815  R2 = 0.9822\n",
            "Epoch 11: loss = 3.2570  R2 = 0.9824\n",
            "Epoch 12: loss = 3.2237  R2 = 0.9825\n",
            "Epoch 13: loss = 3.2068  R2 = 0.9826\n",
            "Epoch 14: loss = 3.1890  R2 = 0.9827\n",
            "Epoch 15: loss = 3.1759  R2 = 0.9828\n",
            "Epoch 16: loss = 3.1619  R2 = 0.9829\n",
            "Epoch 17: loss = 3.1545  R2 = 0.9829\n",
            "Epoch 18: loss = 3.1487  R2 = 0.9829\n",
            "Epoch 19: loss = 3.1445  R2 = 0.9830\n",
            "Epoch 20: loss = 3.1419  R2 = 0.9830\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = evaluate(\"Baseline\", pred_model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_mvrAaRflDM",
        "outputId": "adf64cc6-fc57-473e-9578-4a819c43c5c9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline           RMSE=1.8124 MSE=3.2847 MAE=1.3609 R2=0.6634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple linear prediction"
      ],
      "metadata": {
        "id": "I4Ms57Y4QdG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearPredictionModel(nn.Module):\n",
        "    def __init__(self, in_dim, mae):\n",
        "        super().__init__()\n",
        "        self.mae = mae\n",
        "        self.predictor = nn.Linear(in_dim, 1)\n",
        "\n",
        "        for param in self.mae.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc = self.mae.encoder(x)\n",
        "        return self.predictor(enc)\n",
        "\n",
        "pred_model = LinearPredictionModel(in_dim=128, mae=model).cuda()\n",
        "pred_model.predictor.apply(initialize_weights)\n",
        "_ = train(pred_model, train_loader, n_epochs=30, lr=1e-4)"
      ],
      "metadata": {
        "id": "f-NRDxt5QfFA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f93539e-bcc6-4e2a-84f5-c549effdebb0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss = 479.9072  R2 = -1.6007\n",
            "Epoch 2: loss = 440.6416  R2 = -1.3879\n",
            "Epoch 3: loss = 404.0756  R2 = -1.1897\n",
            "Epoch 4: loss = 370.1533  R2 = -1.0059\n",
            "Epoch 5: loss = 338.8707  R2 = -0.8363\n",
            "Epoch 6: loss = 310.1029  R2 = -0.6805\n",
            "Epoch 7: loss = 283.7923  R2 = -0.5379\n",
            "Epoch 8: loss = 259.8236  R2 = -0.4080\n",
            "Epoch 9: loss = 238.0824  R2 = -0.2901\n",
            "Epoch 10: loss = 218.4634  R2 = -0.1838\n",
            "Epoch 11: loss = 200.8353  R2 = -0.0883\n",
            "Epoch 12: loss = 185.0870  R2 = -0.0029\n",
            "Epoch 13: loss = 171.0730  R2 = 0.0730\n",
            "Epoch 14: loss = 158.6835  R2 = 0.1401\n",
            "Epoch 15: loss = 147.7881  R2 = 0.1991\n",
            "Epoch 16: loss = 138.2665  R2 = 0.2507\n",
            "Epoch 17: loss = 129.9996  R2 = 0.2955\n",
            "Epoch 18: loss = 122.8840  R2 = 0.3341\n",
            "Epoch 19: loss = 116.8036  R2 = 0.3670\n",
            "Epoch 20: loss = 111.6687  R2 = 0.3949\n",
            "Epoch 21: loss = 107.3883  R2 = 0.4181\n",
            "Epoch 22: loss = 103.8732  R2 = 0.4371\n",
            "Epoch 23: loss = 101.0429  R2 = 0.4524\n",
            "Epoch 24: loss = 98.8290  R2 = 0.4644\n",
            "Epoch 25: loss = 97.1535  R2 = 0.4735\n",
            "Epoch 26: loss = 95.9398  R2 = 0.4801\n",
            "Epoch 27: loss = 95.1171  R2 = 0.4846\n",
            "Epoch 28: loss = 94.6076  R2 = 0.4873\n",
            "Epoch 29: loss = 94.3411  R2 = 0.4888\n",
            "Epoch 30: loss = 94.2361  R2 = 0.4893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = evaluate(\"Linear prediction\", pred_model, test_loader)"
      ],
      "metadata": {
        "id": "o-9YIel9QvVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fce5dafc-b63a-4c2e-9ed8-74554cd47bf7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear prediction  RMSE=7.5521 MSE=57.0344 MAE=6.8655 R2=-4.8447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-layer linear prediction"
      ],
      "metadata": {
        "id": "mY1iaQqaQv2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiLinearPredictionModel(nn.Module):\n",
        "    def __init__(self, in_dim, mae):\n",
        "        super().__init__()\n",
        "        self.mae = mae\n",
        "        self.predictor = nn.Sequential(\n",
        "            nn.Linear(in_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "        for param in self.mae.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc = self.mae.encoder(x)\n",
        "        return self.predictor(enc)\n",
        "\n",
        "pred_model = MultiLinearPredictionModel(in_dim=128, mae=model).cuda()\n",
        "pred_model.predictor.apply(initialize_weights)\n",
        "_ = train(pred_model, train_loader, n_epochs=20, lr=1e-4)"
      ],
      "metadata": {
        "id": "Bjb8edsFQ0KB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6cf7c7e-80f2-4640-fff8-4807d9b022fa"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss = 378.9284  R2 = -1.0535\n",
            "Epoch 2: loss = 145.4503  R2 = 0.2117\n",
            "Epoch 3: loss = 33.3476  R2 = 0.8193\n",
            "Epoch 4: loss = 14.2146  R2 = 0.9230\n",
            "Epoch 5: loss = 11.0473  R2 = 0.9401\n",
            "Epoch 6: loss = 9.3514  R2 = 0.9493\n",
            "Epoch 7: loss = 8.2026  R2 = 0.9556\n",
            "Epoch 8: loss = 7.4188  R2 = 0.9598\n",
            "Epoch 9: loss = 6.8707  R2 = 0.9628\n",
            "Epoch 10: loss = 6.4880  R2 = 0.9648\n",
            "Epoch 11: loss = 6.2174  R2 = 0.9663\n",
            "Epoch 12: loss = 6.0170  R2 = 0.9674\n",
            "Epoch 13: loss = 5.8689  R2 = 0.9682\n",
            "Epoch 14: loss = 5.7575  R2 = 0.9688\n",
            "Epoch 15: loss = 5.6760  R2 = 0.9692\n",
            "Epoch 16: loss = 5.6169  R2 = 0.9696\n",
            "Epoch 17: loss = 5.5776  R2 = 0.9698\n",
            "Epoch 18: loss = 5.5524  R2 = 0.9699\n",
            "Epoch 19: loss = 5.5401  R2 = 0.9700\n",
            "Epoch 20: loss = 5.5344  R2 = 0.9700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = evaluate(\"Multi-layer linear prediction\", pred_model, test_loader)"
      ],
      "metadata": {
        "id": "i71kgjbJRLKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf88f2a-4af6-4313-d233-a11385a5ac34"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-layer linear prediction RMSE=3.5767 MSE=12.7930 MAE=2.7154 R2=-0.3110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear+Dropout prediction"
      ],
      "metadata": {
        "id": "AHXFDgcAQ_6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DropoutLinearPredictionModel(nn.Module):\n",
        "    def __init__(self, in_dim, mae, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.mae = mae\n",
        "        self.predictor = nn.Sequential(\n",
        "            nn.LayerNorm(in_dim),\n",
        "            nn.Linear(in_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),           # Reduced from 0.5 to avoid underfitting\n",
        "            nn.Linear(256, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout / 2),       # Add dropout between deeper layers\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "        for param in self.mae.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc = self.mae.encoder(x)\n",
        "        return self.predictor(enc)\n",
        "\n",
        "pred_model = DropoutLinearPredictionModel(in_dim=128, mae=model).cuda()\n",
        "pred_model.predictor.apply(initialize_weights)\n",
        "_ = train(pred_model, train_loader, n_epochs=20, lr=1e-4, gradient_clipping=True)"
      ],
      "metadata": {
        "id": "Oq8F8ANLRCut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19163ca4-b60a-4974-d3ee-7d604bbd33cb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss = 110.8870  R2 = 0.3989\n",
            "Epoch 2: loss = 10.2707  R2 = 0.9443\n",
            "Epoch 3: loss = 9.3712  R2 = 0.9492\n",
            "Epoch 4: loss = 8.9942  R2 = 0.9513\n",
            "Epoch 5: loss = 8.6386  R2 = 0.9532\n",
            "Epoch 6: loss = 8.5181  R2 = 0.9538\n",
            "Epoch 7: loss = 8.4046  R2 = 0.9545\n",
            "Epoch 8: loss = 8.2600  R2 = 0.9552\n",
            "Epoch 9: loss = 8.1469  R2 = 0.9559\n",
            "Epoch 10: loss = 8.0602  R2 = 0.9563\n",
            "Epoch 11: loss = 8.1160  R2 = 0.9560\n",
            "Epoch 12: loss = 7.9845  R2 = 0.9567\n",
            "Epoch 13: loss = 7.9477  R2 = 0.9569\n",
            "Epoch 14: loss = 7.9492  R2 = 0.9569\n",
            "Epoch 15: loss = 7.9491  R2 = 0.9569\n",
            "Epoch 16: loss = 7.9156  R2 = 0.9571\n",
            "Epoch 17: loss = 7.9260  R2 = 0.9570\n",
            "Epoch 18: loss = 7.8732  R2 = 0.9573\n",
            "Epoch 19: loss = 7.8683  R2 = 0.9574\n",
            "Epoch 20: loss = 7.8517  R2 = 0.9575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = evaluate(\"Dropout+linear prediction\", pred_model, test_loader)"
      ],
      "metadata": {
        "id": "Ur1Okwd8RROg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b30e3ea0-373e-41c3-85dd-cf63cd84ecbc"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropout+linear prediction RMSE=2.9876 MSE=8.9257 MAE=2.4747 R2=0.0853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deeper Droput prediction"
      ],
      "metadata": {
        "id": "TfzqDB_mcS5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepDropoutLinearPredictionModel(nn.Module):\n",
        "    def __init__(self, in_dim, mae, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.mae = mae\n",
        "\n",
        "        # Freeze MAE if needed\n",
        "        for param in self.mae.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.predictor = nn.Sequential(\n",
        "            nn.LayerNorm(in_dim),\n",
        "            nn.Linear(in_dim, 256),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.LayerNorm(256),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.LayerNorm(128),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout / 2),\n",
        "\n",
        "            nn.Linear(64, 32),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout / 2),\n",
        "\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc = self.mae.encoder(x)  # (B, D)\n",
        "        return self.predictor(enc).squeeze(-1)  # (B,)\n",
        "\n",
        "pred_model = DeepDropoutLinearPredictionModel(in_dim=128, mae=model).cuda()\n",
        "pred_model.predictor.apply(initialize_weights)\n",
        "_ = train(pred_model, train_loader, n_epochs=20, lr=1e-4, weight_decay=5e-4, gradient_clipping=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzTgxiFBcVRW",
        "outputId": "4535c8d3-9b3f-4ddd-e927-348e73b0496b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss = 144.5541  R2 = 0.2165\n",
            "Epoch 2: loss = 19.0636  R2 = 0.8967\n",
            "Epoch 3: loss = 15.7416  R2 = 0.9147\n",
            "Epoch 4: loss = 14.3331  R2 = 0.9223\n",
            "Epoch 5: loss = 13.5232  R2 = 0.9267\n",
            "Epoch 6: loss = 12.9884  R2 = 0.9296\n",
            "Epoch 7: loss = 12.5257  R2 = 0.9321\n",
            "Epoch 8: loss = 12.2175  R2 = 0.9338\n",
            "Epoch 9: loss = 11.9450  R2 = 0.9353\n",
            "Epoch 10: loss = 11.7600  R2 = 0.9363\n",
            "Epoch 11: loss = 11.6318  R2 = 0.9370\n",
            "Epoch 12: loss = 11.3515  R2 = 0.9385\n",
            "Epoch 13: loss = 11.2154  R2 = 0.9392\n",
            "Epoch 14: loss = 11.1137  R2 = 0.9398\n",
            "Epoch 15: loss = 11.1923  R2 = 0.9393\n",
            "Epoch 16: loss = 11.0620  R2 = 0.9401\n",
            "Epoch 17: loss = 11.0748  R2 = 0.9400\n",
            "Epoch 18: loss = 10.9841  R2 = 0.9405\n",
            "Epoch 19: loss = 11.0474  R2 = 0.9401\n",
            "Epoch 20: loss = 11.1376  R2 = 0.9396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = evaluate(\"Deep dropout+linear prediction\", pred_model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqC58ir2cb2B",
        "outputId": "a1bac14c-5dcc-4b0e-d98d-6b913d22f9b7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep dropout+linear prediction RMSE=3.6035 MSE=12.9855 MAE=2.6570 R2=-0.3307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GELU prediction"
      ],
      "metadata": {
        "id": "M9R_V6VdRSeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GELUPredictionModel(nn.Module):\n",
        "    def __init__(self, in_dim, mae):\n",
        "        super().__init__()\n",
        "        self.mae = mae\n",
        "        self.predictor = nn.Sequential(\n",
        "            nn.LayerNorm(128),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "        for param in self.mae.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc = self.mae.encoder(x)\n",
        "        return self.predictor(enc)\n",
        "\n",
        "pred_model = GELUPredictionModel(in_dim=128, mae=model).cuda()\n",
        "pred_model.predictor.apply(initialize_weights)\n",
        "_ = train(pred_model, train_loader, n_epochs=20, lr=1e-4)"
      ],
      "metadata": {
        "id": "qbY4FjhIRWXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb3a8b8-adf2-4b98-f3c4-b017afc038ef"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss = 103.6273  R2 = 0.4383\n",
            "Epoch 2: loss = 11.2845  R2 = 0.9388\n",
            "Epoch 3: loss = 9.8866  R2 = 0.9464\n",
            "Epoch 4: loss = 9.2162  R2 = 0.9501\n",
            "Epoch 5: loss = 8.6010  R2 = 0.9534\n",
            "Epoch 6: loss = 8.3138  R2 = 0.9549\n",
            "Epoch 7: loss = 7.9841  R2 = 0.9567\n",
            "Epoch 8: loss = 7.7322  R2 = 0.9581\n",
            "Epoch 9: loss = 7.6176  R2 = 0.9587\n",
            "Epoch 10: loss = 7.3985  R2 = 0.9599\n",
            "Epoch 11: loss = 7.3076  R2 = 0.9604\n",
            "Epoch 12: loss = 7.2029  R2 = 0.9610\n",
            "Epoch 13: loss = 7.1132  R2 = 0.9615\n",
            "Epoch 14: loss = 7.0982  R2 = 0.9615\n",
            "Epoch 15: loss = 7.0711  R2 = 0.9617\n",
            "Epoch 16: loss = 6.9525  R2 = 0.9623\n",
            "Epoch 17: loss = 6.9288  R2 = 0.9625\n",
            "Epoch 18: loss = 6.9910  R2 = 0.9621\n",
            "Epoch 19: loss = 6.9265  R2 = 0.9625\n",
            "Epoch 20: loss = 6.9338  R2 = 0.9624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = evaluate(\"GELU prediction\", pred_model, test_loader)"
      ],
      "metadata": {
        "id": "kJJtd_5KRmac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6cba937-fcea-484a-b8ee-fb974f7e4464"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GELU prediction    RMSE=3.1991 MSE=10.2341 MAE=2.3228 R2=-0.0488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Residual Block prediction"
      ],
      "metadata": {
        "id": "yzkLJTOARndK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, dim, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim, dim),\n",
        "        )\n",
        "        self.ln = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.ln(x + self.block(x))\n",
        "\n",
        "class ResidualPredictionModel(nn.Module):\n",
        "    def __init__(self, in_dim, mae):\n",
        "        super().__init__()\n",
        "        self.mae = mae\n",
        "\n",
        "        for param in self.mae.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.input_proj = nn.Sequential(\n",
        "            nn.LayerNorm(in_dim),\n",
        "            nn.Linear(in_dim, 256),\n",
        "            nn.SiLU()\n",
        "        )\n",
        "\n",
        "        self.residual_blocks = nn.Sequential(\n",
        "            ResidualBlock(256, dropout=0.3),\n",
        "            ResidualBlock(256, dropout=0.2)\n",
        "        )\n",
        "\n",
        "        self.output_head = nn.Sequential(\n",
        "            nn.Linear(256, 128),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc = self.mae.encoder(x)  # (B, D)\n",
        "        x = self.input_proj(enc)   # (B, 256)\n",
        "        x = self.residual_blocks(x)\n",
        "        return self.output_head(x)\n",
        "\n",
        "pred_model = ResidualPredictionModel(in_dim=128, mae=model).cuda()\n",
        "pred_model.input_proj.apply(initialize_weights)\n",
        "pred_model.output_head.apply(initialize_weights)\n",
        "pred_model.residual_blocks.apply(initialize_weights)\n",
        "_ = train(pred_model, train_loader, n_epochs=20, lr=1e-4)"
      ],
      "metadata": {
        "id": "JitilkfrRpfu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f0d5969-79e2-4990-8f48-904129aa0672"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss = 43.3780  R2 = 0.7649\n",
            "Epoch 2: loss = 7.5255  R2 = 0.9592\n",
            "Epoch 3: loss = 6.4956  R2 = 0.9648\n",
            "Epoch 4: loss = 6.0274  R2 = 0.9673\n",
            "Epoch 5: loss = 5.7452  R2 = 0.9689\n",
            "Epoch 6: loss = 5.5547  R2 = 0.9699\n",
            "Epoch 7: loss = 5.4313  R2 = 0.9706\n",
            "Epoch 8: loss = 5.3098  R2 = 0.9712\n",
            "Epoch 9: loss = 5.2195  R2 = 0.9717\n",
            "Epoch 10: loss = 5.1948  R2 = 0.9719\n",
            "Epoch 11: loss = 5.0849  R2 = 0.9724\n",
            "Epoch 12: loss = 5.0400  R2 = 0.9727\n",
            "Epoch 13: loss = 4.9631  R2 = 0.9731\n",
            "Epoch 14: loss = 4.9658  R2 = 0.9731\n",
            "Epoch 15: loss = 4.8876  R2 = 0.9735\n",
            "Epoch 16: loss = 4.9142  R2 = 0.9734\n",
            "Epoch 17: loss = 4.8544  R2 = 0.9737\n",
            "Epoch 18: loss = 4.8387  R2 = 0.9738\n",
            "Epoch 19: loss = 4.8457  R2 = 0.9737\n",
            "Epoch 20: loss = 4.8250  R2 = 0.9739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = evaluate(\"Residual prediction\", pred_model, test_loader)"
      ],
      "metadata": {
        "id": "9tnpHZEAR6g9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb0520a0-efb2-4a3e-d452-1c0c16cbfc37"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Residual prediction RMSE=3.2078 MSE=10.2899 MAE=2.6218 R2=-0.0545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_model = ResidualPredictionModel(in_dim=128, mae=model).cuda()\n",
        "pred_model.input_proj.apply(initialize_weights)\n",
        "pred_model.output_head.apply(initialize_weights)\n",
        "pred_model.residual_blocks.apply(initialize_weights)\n",
        "_ = train(pred_model, train_loader, n_epochs=50, lr=1e-4)\n",
        "_ = evaluate(\"Residual prediction\", pred_model, test_loader)"
      ],
      "metadata": {
        "id": "LJ1tKmvhR84a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c02bb68-be75-42da-f983-9f30c62f4f8c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss = 47.2494  R2 = 0.7439\n",
            "Epoch 2: loss = 7.5836  R2 = 0.9589\n",
            "Epoch 3: loss = 6.5905  R2 = 0.9643\n",
            "Epoch 4: loss = 6.1428  R2 = 0.9667\n",
            "Epoch 5: loss = 5.8642  R2 = 0.9682\n",
            "Epoch 6: loss = 5.6376  R2 = 0.9694\n",
            "Epoch 7: loss = 5.5057  R2 = 0.9702\n",
            "Epoch 8: loss = 5.3536  R2 = 0.9710\n",
            "Epoch 9: loss = 5.2710  R2 = 0.9714\n",
            "Epoch 10: loss = 5.1633  R2 = 0.9720\n",
            "Epoch 11: loss = 5.0813  R2 = 0.9725\n",
            "Epoch 12: loss = 5.0330  R2 = 0.9727\n",
            "Epoch 13: loss = 4.9812  R2 = 0.9730\n",
            "Epoch 14: loss = 4.8704  R2 = 0.9736\n",
            "Epoch 15: loss = 4.8329  R2 = 0.9738\n",
            "Epoch 16: loss = 4.7913  R2 = 0.9740\n",
            "Epoch 17: loss = 4.7459  R2 = 0.9743\n",
            "Epoch 18: loss = 4.6979  R2 = 0.9745\n",
            "Epoch 19: loss = 4.6747  R2 = 0.9747\n",
            "Epoch 20: loss = 4.5873  R2 = 0.9751\n",
            "Epoch 21: loss = 4.5660  R2 = 0.9753\n",
            "Epoch 22: loss = 4.5168  R2 = 0.9755\n",
            "Epoch 23: loss = 4.4703  R2 = 0.9758\n",
            "Epoch 24: loss = 4.4300  R2 = 0.9760\n",
            "Epoch 25: loss = 4.4239  R2 = 0.9760\n",
            "Epoch 26: loss = 4.4051  R2 = 0.9761\n",
            "Epoch 27: loss = 4.3675  R2 = 0.9763\n",
            "Epoch 28: loss = 4.3548  R2 = 0.9764\n",
            "Epoch 29: loss = 4.3197  R2 = 0.9766\n",
            "Epoch 30: loss = 4.2915  R2 = 0.9767\n",
            "Epoch 31: loss = 4.2832  R2 = 0.9768\n",
            "Epoch 32: loss = 4.2734  R2 = 0.9768\n",
            "Epoch 33: loss = 4.2170  R2 = 0.9771\n",
            "Epoch 34: loss = 4.2090  R2 = 0.9772\n",
            "Epoch 35: loss = 4.2085  R2 = 0.9772\n",
            "Epoch 36: loss = 4.1960  R2 = 0.9773\n",
            "Epoch 37: loss = 4.1924  R2 = 0.9773\n",
            "Epoch 38: loss = 4.1763  R2 = 0.9774\n",
            "Epoch 39: loss = 4.1698  R2 = 0.9774\n",
            "Epoch 40: loss = 4.1527  R2 = 0.9775\n",
            "Epoch 41: loss = 4.1717  R2 = 0.9774\n",
            "Epoch 42: loss = 4.1664  R2 = 0.9774\n",
            "Epoch 43: loss = 4.1312  R2 = 0.9776\n",
            "Epoch 44: loss = 4.1310  R2 = 0.9776\n",
            "Epoch 45: loss = 4.1744  R2 = 0.9774\n",
            "Epoch 46: loss = 4.1220  R2 = 0.9777\n",
            "Epoch 47: loss = 4.1493  R2 = 0.9775\n",
            "Epoch 48: loss = 4.1451  R2 = 0.9775\n",
            "Epoch 49: loss = 4.1368  R2 = 0.9776\n",
            "Epoch 50: loss = 4.1642  R2 = 0.9774\n",
            "Residual prediction RMSE=3.4323 MSE=11.7804 MAE=2.8147 R2=-0.2072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tq2LAuZ9aQcT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}