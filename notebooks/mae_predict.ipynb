{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JBPskR0TNpIn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model loading"
      ],
      "metadata": {
        "id": "3hac5eUTPth6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedAutoEncoder(nn.Module):\n",
        "    def __init__(self, in_dim=9, maskable_dim=4, embed_dim=64, depth=4):\n",
        "        super().__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.maskable_dim = maskable_dim\n",
        "\n",
        "        self.mask_token = nn.Parameter(torch.zeros(in_dim))\n",
        "\n",
        "        layers = []\n",
        "        for _ in range(depth):\n",
        "            layers += [\n",
        "                nn.Linear(embed_dim if layers else in_dim, embed_dim),\n",
        "                nn.GELU(),\n",
        "                nn.LayerNorm(embed_dim)\n",
        "            ]\n",
        "        self.encoder = nn.Sequential(*layers)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(embed_dim, in_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = torch.where(mask, x, self.mask_token)\n",
        "        z = self.encoder(x)\n",
        "        return self.decoder(z)"
      ],
      "metadata": {
        "id": "-gqOAQ0OPP1w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = 'models/model.pt'"
      ],
      "metadata": {
        "id": "bLNnAyPDNxH7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(MODEL_PATH):\n",
        "    print(f\"Loading model from {MODEL_PATH}\")\n",
        "    model = MaskedAutoEncoder(in_dim=9, embed_dim=128).cuda()\n",
        "    model.load_state_dict(torch.load(MODEL_PATH))\n",
        "    model.eval()\n",
        "else:\n",
        "    print(f\"MAE model not found!\")"
      ],
      "metadata": {
        "id": "QY-h_ASzO5lr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204ada52-5f51-4015-9834-e0f9a9246376"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from models/model.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading"
      ],
      "metadata": {
        "id": "VIZ3-V12PwLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet(\"data/processed/nitrate_00_train_data.parquet\")\n",
        "cols = [\"temperature_00\", \"salinity_00\", \"oxygen_00\", \"phosphate_00\"]\n",
        "\n",
        "def encode_geospatial_features(df: pd.DataFrame) -> np.ndarray:\n",
        "    lat_rad = np.radians(df[\"lat\"].to_numpy())\n",
        "    lon_rad = np.radians(df[\"lon\"].to_numpy())\n",
        "\n",
        "    sin_lat = np.sin(lat_rad)\n",
        "    cos_lat = np.cos(lat_rad)\n",
        "    sin_lon = np.sin(lon_rad)\n",
        "    cos_lon = np.cos(lon_rad)\n",
        "\n",
        "    depth = df[\"depth\"].to_numpy(dtype=np.float32)\n",
        "    norm_depth = (depth - depth.min()) / (depth.max() - depth.min())\n",
        "\n",
        "    geo_features = np.stack([sin_lat, cos_lat, sin_lon, cos_lon, norm_depth], axis=1)\n",
        "    return geo_features.astype(np.float32)\n",
        "\n",
        "class Scaler:\n",
        "    def __init__(self, mean: dict[str, float], std: dict[str, float]):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.cols = list(mean.keys())\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, df, cols):\n",
        "        mean = {col: df[col].mean() for col in cols}\n",
        "        std = {col: df[col].std() for col in cols}\n",
        "        return cls(mean, std)\n",
        "\n",
        "    def normalize(self, tensor: torch.Tensor, cols: list[str]) -> torch.Tensor:\n",
        "        for i, col in enumerate(cols):\n",
        "            tensor[:, i] = (tensor[:, i] - self.mean[col]) / self.std[col]\n",
        "        return tensor\n",
        "\n",
        "    def denormalize(self, tensor: torch.Tensor, cols: list[str]) -> torch.Tensor:\n",
        "        means = torch.tensor([self.mean[c] for c in cols], dtype=tensor.dtype, device=tensor.device)\n",
        "        stds  = torch.tensor([self.std[c]  for c in cols], dtype=tensor.dtype, device=tensor.device)\n",
        "        return tensor * stds + means\n",
        "\n",
        "    def mae(self, reconstructed: torch.Tensor, ground_truth: torch.Tensor, cols: list[str]) -> float:\n",
        "        rec_denorm = self.denormalize(reconstructed.clone(), cols)\n",
        "        gt_denorm = self.denormalize(ground_truth.clone(), cols)\n",
        "        return torch.abs(rec_denorm - gt_denorm).mean().item()\n",
        "\n",
        "    def masked_mae(self, reconstructed: torch.Tensor, ground_truth: torch.Tensor, mask: torch.Tensor, cols: list[str]) -> float:\n",
        "        rec_denorm = self.denormalize(reconstructed.clone(), cols)\n",
        "        gt_denorm = self.denormalize(ground_truth.clone(), cols)\n",
        "\n",
        "        abs_error = torch.abs(rec_denorm - gt_denorm)\n",
        "        masked_error = abs_error * mask\n",
        "\n",
        "        mae = masked_error.sum() / mask.sum().clamp(min=1.0)\n",
        "        return mae.item()\n",
        "\n",
        "df = df.dropna(subset=cols).reset_index(drop=True)\n",
        "scaler = Scaler.from_dataframe(df, cols)\n",
        "geo = encode_geospatial_features(df)\n",
        "x = df[cols].to_numpy(dtype=np.float32)\n",
        "\n",
        "x_full = np.concatenate([x, geo], axis=1)\n",
        "\n",
        "X = torch.tensor(x_full)\n",
        "X = scaler.normalize(X.clone(), cols)\n",
        "\n",
        "class PredictionDataset(Dataset):\n",
        "    def __init__(self, X: torch.Tensor, y: torch.Tensor):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "TARGET         = \"nitrate_00\"\n",
        "TEST_BBOX      = {                       # Morze Śródziemne\n",
        "    \"lat_min\": 30.0, \"lat_max\": 46.0,\n",
        "    \"lon_min\": -6.0, \"lon_max\": 36.0\n",
        "}\n",
        "SEED           = 42\n",
        "N_JOBS         = -1\n",
        "SUB_FRAC       = 0.20\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "test_mask = (\n",
        "    (df[\"lat\"].between(TEST_BBOX[\"lat_min\"], TEST_BBOX[\"lat_max\"])) &\n",
        "    (df[\"lon\"].between(TEST_BBOX[\"lon_min\"], TEST_BBOX[\"lon_max\"]))\n",
        ")\n",
        "\n",
        "X_train_large = X[~test_mask, :].clone()\n",
        "X_test = X[test_mask, :].clone()\n",
        "\n",
        "y_train_large = df[~test_mask][TARGET].to_numpy(dtype=np.float32)\n",
        "y_test = df[test_mask][TARGET].to_numpy(dtype=np.float32)\n",
        "\n",
        "print(f\"X_train_large shape: {X_train_large.shape}\")\n",
        "print(f\"y_train_large  shape: {y_train_large.shape}\")\n",
        "\n",
        "idx = np.random.choice(X_train_large.shape[0], int((X_train_large.shape[0])*SUB_FRAC), replace=False)\n",
        "\n",
        "X_train = torch.Tensor(X_train_large[idx])\n",
        "y_train = torch.Tensor(y_train_large[idx])\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test  shape: {X_test.shape}\")\n",
        "\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test  shape: {y_test.shape}\")\n",
        "\n",
        "train_ds = PredictionDataset(X_train, y_train)\n",
        "test_ds  = PredictionDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=len(test_ds), shuffle=False)\n"
      ],
      "metadata": {
        "id": "YUOyThUAPzJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "782b7c08-adde-4577-a1ff-c1dd5f48cf9f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_large shape: torch.Size([601393, 9])\n",
            "y_train_large  shape: (601393,)\n",
            "X_train shape: torch.Size([120278, 9])\n",
            "X_test  shape: torch.Size([8519, 9])\n",
            "y_train shape: torch.Size([120278])\n",
            "y_test  shape: (8519,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop"
      ],
      "metadata": {
        "id": "Vm_m0WcKQS3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model_, loader_, n_epochs=20, lr=1e-3, weight_decay=1e-4, verbose=True, gradient_clipping=False):\n",
        "    opt = torch.optim.Adam(model_.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=n_epochs)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model_.train()\n",
        "        total_loss = 0\n",
        "        all_y = []\n",
        "        all_pred = []\n",
        "\n",
        "        for x, y in loader_:\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "            pred = model_(x).flatten()\n",
        "\n",
        "            loss = loss_fn(pred, y)\n",
        "            loss.backward()\n",
        "\n",
        "            if gradient_clipping:\n",
        "                torch.nn.utils.clip_grad_norm_(model_.parameters(), max_norm=1.0)\n",
        "\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            all_y.append(y.detach().cpu())\n",
        "            all_pred.append(pred.detach().cpu())\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Concatenate all predictions and targets\n",
        "        all_y = torch.cat(all_y).numpy()\n",
        "        all_pred = torch.cat(all_pred).numpy()\n",
        "\n",
        "        r2 = r2_score(all_y, all_pred)\n",
        "        avg_loss = total_loss / len(loader_)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch+1}: loss = {avg_loss:.4f}  R2 = {r2:.4f}\")\n",
        "\n",
        "    return avg_loss, r2\n",
        "\n",
        "def metrics(name, y, pred, verbose=True):\n",
        "    mse = mean_squared_error(y, pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae  = mean_absolute_error(y, pred)\n",
        "    r2   = r2_score(y, pred)\n",
        "    if verbose:\n",
        "        print(f\"{name:<18} RMSE={rmse:.4f} MSE={mse:.4f} MAE={mae:.4f} R2={r2:.4f}\")\n",
        "    return mse, rmse, mae, r2\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(name, model_, loader_):\n",
        "    model_.eval()\n",
        "    for x, y in loader_:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "        pred = model_(x).flatten()\n",
        "        y = y.detach().cpu().numpy()\n",
        "        pred = pred.detach().cpu().numpy()\n",
        "        return metrics(name, y, pred)\n",
        "\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)\n",
        "    elif isinstance(m, nn.LayerNorm):\n",
        "        nn.init.ones_(m.weight)\n",
        "        nn.init.zeros_(m.bias)"
      ],
      "metadata": {
        "id": "MCn5PEaHPk5j"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity check: linear prediction without embeddings"
      ],
      "metadata": {
        "id": "40sN9c2ifXB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineMLP(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super().__init__()\n",
        "        self.predictor = nn.Sequential(\n",
        "            nn.Linear(in_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.predictor(x).squeeze(-1)\n",
        "\n",
        "for _ in range(10):\n",
        "    torch.manual_seed(42); torch.cuda.manual_seed_all(42)\n",
        "    pred_model = BaselineMLP(in_dim=9).cuda()\n",
        "    _ = train(pred_model, train_loader, n_epochs=13, lr=1e-3, verbose=False)\n",
        "    _ = evaluate(\"Baseline\", pred_model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU-o-18-fb5d",
        "outputId": "73cbcfd5-88bd-4b5f-f80d-e78046552e84"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline           RMSE=1.7460 MSE=3.0484 MAE=1.4035 R2=0.6876\n",
            "Baseline           RMSE=1.7460 MSE=3.0484 MAE=1.4035 R2=0.6876\n",
            "Baseline           RMSE=1.7460 MSE=3.0484 MAE=1.4035 R2=0.6876\n",
            "Baseline           RMSE=1.7460 MSE=3.0484 MAE=1.4035 R2=0.6876\n",
            "Baseline           RMSE=1.7460 MSE=3.0484 MAE=1.4035 R2=0.6876\n",
            "Baseline           RMSE=1.7460 MSE=3.0484 MAE=1.4035 R2=0.6876\n",
            "Baseline           RMSE=1.7460 MSE=3.0484 MAE=1.4035 R2=0.6876\n",
            "Baseline           RMSE=1.7460 MSE=3.0484 MAE=1.4035 R2=0.6876\n",
            "Baseline           RMSE=1.7460 MSE=3.0484 MAE=1.4035 R2=0.6876\n",
            "Baseline           RMSE=1.7460 MSE=3.0484 MAE=1.4035 R2=0.6876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple linear prediction"
      ],
      "metadata": {
        "id": "I4Ms57Y4QdG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearPredictionModel(nn.Module):\n",
        "    def __init__(self, in_dim, mae):\n",
        "        super().__init__()\n",
        "        self.mae = mae\n",
        "        self.predictor = nn.Linear(in_dim, 1)\n",
        "\n",
        "        for param in self.mae.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc = self.mae.encoder(x)\n",
        "        return self.predictor(enc)\n",
        "\n",
        "torch.manual_seed(42); torch.cuda.manual_seed_all(42)\n",
        "pred_model = LinearPredictionModel(in_dim=128, mae=model).cuda()\n",
        "pred_model.predictor.apply(initialize_weights)\n",
        "_ = train(pred_model, train_loader, n_epochs=30, lr=1e-4)"
      ],
      "metadata": {
        "id": "f-NRDxt5QfFA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34aea319-9196-4a39-9da2-dbe617740875"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss = 440.3712  R2 = -1.3863\n",
            "Epoch 2: loss = 402.6417  R2 = -1.1819\n",
            "Epoch 3: loss = 367.7134  R2 = -0.9926\n",
            "Epoch 4: loss = 335.4680  R2 = -0.8179\n",
            "Epoch 5: loss = 305.7920  R2 = -0.6571\n",
            "Epoch 6: loss = 278.6206  R2 = -0.5098\n",
            "Epoch 7: loss = 253.8073  R2 = -0.3754\n",
            "Epoch 8: loss = 231.2943  R2 = -0.2534\n",
            "Epoch 9: loss = 210.9531  R2 = -0.1431\n",
            "Epoch 10: loss = 192.6362  R2 = -0.0439\n",
            "Epoch 11: loss = 176.2463  R2 = 0.0450\n",
            "Epoch 12: loss = 161.6234  R2 = 0.1242\n",
            "Epoch 13: loss = 148.6730  R2 = 0.1944\n",
            "Epoch 14: loss = 137.2514  R2 = 0.2562\n",
            "Epoch 15: loss = 127.2473  R2 = 0.3105\n",
            "Epoch 16: loss = 118.5088  R2 = 0.3578\n",
            "Epoch 17: loss = 110.9615  R2 = 0.3987\n",
            "Epoch 18: loss = 104.4755  R2 = 0.4338\n",
            "Epoch 19: loss = 98.9636  R2 = 0.4638\n",
            "Epoch 20: loss = 94.3029  R2 = 0.4890\n",
            "Epoch 21: loss = 90.4308  R2 = 0.5100\n",
            "Epoch 22: loss = 87.2564  R2 = 0.5272\n",
            "Epoch 23: loss = 84.7093  R2 = 0.5410\n",
            "Epoch 24: loss = 82.7167  R2 = 0.5518\n",
            "Epoch 25: loss = 81.2037  R2 = 0.5600\n",
            "Epoch 26: loss = 80.1112  R2 = 0.5659\n",
            "Epoch 27: loss = 79.3699  R2 = 0.5699\n",
            "Epoch 28: loss = 78.9146  R2 = 0.5724\n",
            "Epoch 29: loss = 78.6780  R2 = 0.5737\n",
            "Epoch 30: loss = 78.5788  R2 = 0.5742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = evaluate(\"Linear prediction\", pred_model, test_loader)"
      ],
      "metadata": {
        "id": "o-9YIel9QvVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9695eff-ac0d-45b9-e9bb-92536ddb7fab"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear prediction  RMSE=6.6740 MSE=44.5425 MAE=6.0153 R2=-3.5646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-layer linear prediction"
      ],
      "metadata": {
        "id": "mY1iaQqaQv2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiLinearPredictionModel(nn.Module):\n",
        "    def __init__(self, in_dim, mae):\n",
        "        super().__init__()\n",
        "        self.mae = mae\n",
        "        self.predictor = nn.Sequential(\n",
        "            nn.Linear(in_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "        for param in self.mae.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc = self.mae.encoder(x)\n",
        "        return self.predictor(enc)\n",
        "\n",
        "torch.manual_seed(42); torch.cuda.manual_seed_all(42)\n",
        "pred_model = MultiLinearPredictionModel(in_dim=128, mae=model).cuda()\n",
        "pred_model.predictor.apply(initialize_weights)\n",
        "_ = train(pred_model, train_loader, n_epochs=20, lr=1e-4)"
      ],
      "metadata": {
        "id": "Bjb8edsFQ0KB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f65cbbe4-5bc1-4e97-d6b7-a2dd6e6386dc"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss = 344.0143  R2 = -0.8644\n",
            "Epoch 2: loss = 96.0309  R2 = 0.4795\n",
            "Epoch 3: loss = 20.0958  R2 = 0.8911\n",
            "Epoch 4: loss = 11.9658  R2 = 0.9352\n",
            "Epoch 5: loss = 9.8705  R2 = 0.9465\n",
            "Epoch 6: loss = 8.5703  R2 = 0.9536\n",
            "Epoch 7: loss = 7.7079  R2 = 0.9582\n",
            "Epoch 8: loss = 7.1210  R2 = 0.9614\n",
            "Epoch 9: loss = 6.7034  R2 = 0.9637\n",
            "Epoch 10: loss = 6.3939  R2 = 0.9654\n",
            "Epoch 11: loss = 6.1655  R2 = 0.9666\n",
            "Epoch 12: loss = 5.9914  R2 = 0.9675\n",
            "Epoch 13: loss = 5.8575  R2 = 0.9683\n",
            "Epoch 14: loss = 5.7549  R2 = 0.9688\n",
            "Epoch 15: loss = 5.6777  R2 = 0.9692\n",
            "Epoch 16: loss = 5.6212  R2 = 0.9695\n",
            "Epoch 17: loss = 5.5830  R2 = 0.9697\n",
            "Epoch 18: loss = 5.5587  R2 = 0.9699\n",
            "Epoch 19: loss = 5.5469  R2 = 0.9699\n",
            "Epoch 20: loss = 5.5412  R2 = 0.9700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = evaluate(\"Multi-layer linear prediction\", pred_model, test_loader)"
      ],
      "metadata": {
        "id": "i71kgjbJRLKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3275038-1db4-4a38-b905-116623d145fa"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-layer linear prediction RMSE=4.8045 MSE=23.0828 MAE=4.0504 R2=-1.3655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear+Dropout prediction"
      ],
      "metadata": {
        "id": "AHXFDgcAQ_6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DropoutLinearPredictionModel(nn.Module):\n",
        "    def __init__(self, in_dim, mae, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.mae = mae\n",
        "        self.predictor = nn.Sequential(\n",
        "            nn.LayerNorm(in_dim),\n",
        "            nn.Linear(in_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),           # Reduced from 0.5 to avoid underfitting\n",
        "            nn.Linear(256, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout / 2),       # Add dropout between deeper layers\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "        for param in self.mae.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc = self.mae.encoder(x)\n",
        "        return self.predictor(enc)\n",
        "\n",
        "torch.manual_seed(42); torch.cuda.manual_seed_all(42)\n",
        "pred_model = DropoutLinearPredictionModel(in_dim=128, mae=model).cuda()\n",
        "pred_model.predictor.apply(initialize_weights)\n",
        "_ = train(pred_model, train_loader, n_epochs=20, lr=1e-4, gradient_clipping=True)"
      ],
      "metadata": {
        "id": "Oq8F8ANLRCut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c047232-def5-4375-98d1-b243ff9bcfa6"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss = 98.4124  R2 = 0.4666\n",
            "Epoch 2: loss = 9.8125  R2 = 0.9468\n",
            "Epoch 3: loss = 8.8859  R2 = 0.9518\n",
            "Epoch 4: loss = 8.5097  R2 = 0.9539\n",
            "Epoch 5: loss = 8.2663  R2 = 0.9552\n",
            "Epoch 6: loss = 8.0497  R2 = 0.9564\n",
            "Epoch 7: loss = 7.8850  R2 = 0.9573\n",
            "Epoch 8: loss = 7.7623  R2 = 0.9579\n",
            "Epoch 9: loss = 7.6949  R2 = 0.9583\n",
            "Epoch 10: loss = 7.6750  R2 = 0.9584\n",
            "Epoch 11: loss = 7.5781  R2 = 0.9589\n",
            "Epoch 12: loss = 7.5043  R2 = 0.9593\n",
            "Epoch 13: loss = 7.4382  R2 = 0.9597\n",
            "Epoch 14: loss = 7.4180  R2 = 0.9598\n",
            "Epoch 15: loss = 7.3671  R2 = 0.9601\n",
            "Epoch 16: loss = 7.4033  R2 = 0.9599\n",
            "Epoch 17: loss = 7.3678  R2 = 0.9601\n",
            "Epoch 18: loss = 7.4227  R2 = 0.9598\n",
            "Epoch 19: loss = 7.3792  R2 = 0.9600\n",
            "Epoch 20: loss = 7.3601  R2 = 0.9601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = evaluate(\"Dropout+linear prediction\", pred_model, test_loader)"
      ],
      "metadata": {
        "id": "Ur1Okwd8RROg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b03bcdf-585f-4319-e8b1-fd1cf5869038"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropout+linear prediction RMSE=2.4771 MSE=6.1361 MAE=1.9888 R2=0.3712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deeper Droput prediction"
      ],
      "metadata": {
        "id": "TfzqDB_mcS5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepDropoutLinearPredictionModel(nn.Module):\n",
        "    def __init__(self, in_dim, mae, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.mae = mae\n",
        "\n",
        "        # Freeze MAE if needed\n",
        "        for param in self.mae.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.predictor = nn.Sequential(\n",
        "            nn.LayerNorm(in_dim),\n",
        "            nn.Linear(in_dim, 256),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.LayerNorm(256),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.LayerNorm(128),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout / 2),\n",
        "\n",
        "            nn.Linear(64, 32),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout / 2),\n",
        "\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc = self.mae.encoder(x)  # (B, D)\n",
        "        return self.predictor(enc).squeeze(-1)  # (B,)\n",
        "\n",
        "torch.manual_seed(42); torch.cuda.manual_seed_all(42)\n",
        "pred_model = DeepDropoutLinearPredictionModel(in_dim=128, mae=model).cuda()\n",
        "pred_model.predictor.apply(initialize_weights)\n",
        "_ = train(pred_model, train_loader, n_epochs=20, lr=1e-4, weight_decay=5e-4, gradient_clipping=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzTgxiFBcVRW",
        "outputId": "3b4db97e-c6f0-42e0-f011-773642d4d66c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss = 166.2842  R2 = 0.0987\n",
            "Epoch 2: loss = 20.2856  R2 = 0.8901\n",
            "Epoch 3: loss = 17.0555  R2 = 0.9076\n",
            "Epoch 4: loss = 15.5918  R2 = 0.9155\n",
            "Epoch 5: loss = 14.8171  R2 = 0.9197\n",
            "Epoch 6: loss = 14.1695  R2 = 0.9232\n",
            "Epoch 7: loss = 13.6580  R2 = 0.9260\n",
            "Epoch 8: loss = 13.3592  R2 = 0.9276\n",
            "Epoch 9: loss = 13.0840  R2 = 0.9291\n",
            "Epoch 10: loss = 12.8278  R2 = 0.9305\n",
            "Epoch 11: loss = 12.6100  R2 = 0.9317\n",
            "Epoch 12: loss = 12.3367  R2 = 0.9331\n",
            "Epoch 13: loss = 12.2020  R2 = 0.9339\n",
            "Epoch 14: loss = 12.0326  R2 = 0.9348\n",
            "Epoch 15: loss = 12.0572  R2 = 0.9347\n",
            "Epoch 16: loss = 12.0316  R2 = 0.9348\n",
            "Epoch 17: loss = 11.9318  R2 = 0.9353\n",
            "Epoch 18: loss = 11.9596  R2 = 0.9352\n",
            "Epoch 19: loss = 11.9422  R2 = 0.9353\n",
            "Epoch 20: loss = 11.9955  R2 = 0.9350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = evaluate(\"Deep dropout+linear prediction\", pred_model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqC58ir2cb2B",
        "outputId": "44023a83-a4b7-43ab-c79b-6315e7936d26"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep dropout+linear prediction RMSE=3.5695 MSE=12.7410 MAE=2.6521 R2=-0.3057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GELU prediction"
      ],
      "metadata": {
        "id": "M9R_V6VdRSeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GELUPredictionModel(nn.Module):\n",
        "    def __init__(self, in_dim, mae):\n",
        "        super().__init__()\n",
        "        self.mae = mae\n",
        "        self.predictor = nn.Sequential(\n",
        "            nn.LayerNorm(128),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "        for param in self.mae.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc = self.mae.encoder(x)\n",
        "        return self.predictor(enc)\n",
        "\n",
        "torch.manual_seed(42); torch.cuda.manual_seed_all(42)\n",
        "pred_model = GELUPredictionModel(in_dim=128, mae=model).cuda()\n",
        "pred_model.predictor.apply(initialize_weights)\n",
        "_ = train(pred_model, train_loader, n_epochs=20, lr=1e-4)"
      ],
      "metadata": {
        "id": "qbY4FjhIRWXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9142a2fc-637c-41e9-a710-129e1ea2b5c6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss = 96.7575  R2 = 0.4755\n",
            "Epoch 2: loss = 11.1466  R2 = 0.9396\n",
            "Epoch 3: loss = 9.8448  R2 = 0.9467\n",
            "Epoch 4: loss = 9.0926  R2 = 0.9507\n",
            "Epoch 5: loss = 8.5818  R2 = 0.9535\n",
            "Epoch 6: loss = 8.1666  R2 = 0.9557\n",
            "Epoch 7: loss = 7.8592  R2 = 0.9574\n",
            "Epoch 8: loss = 7.6489  R2 = 0.9586\n",
            "Epoch 9: loss = 7.4292  R2 = 0.9597\n",
            "Epoch 10: loss = 7.3237  R2 = 0.9603\n",
            "Epoch 11: loss = 7.1841  R2 = 0.9611\n",
            "Epoch 12: loss = 7.0667  R2 = 0.9617\n",
            "Epoch 13: loss = 7.0068  R2 = 0.9620\n",
            "Epoch 14: loss = 6.9394  R2 = 0.9624\n",
            "Epoch 15: loss = 6.8988  R2 = 0.9626\n",
            "Epoch 16: loss = 6.8430  R2 = 0.9629\n",
            "Epoch 17: loss = 6.8424  R2 = 0.9629\n",
            "Epoch 18: loss = 6.8251  R2 = 0.9630\n",
            "Epoch 19: loss = 6.8238  R2 = 0.9630\n",
            "Epoch 20: loss = 6.7839  R2 = 0.9632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = evaluate(\"GELU prediction\", pred_model, test_loader)"
      ],
      "metadata": {
        "id": "kJJtd_5KRmac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22fd9e77-176d-4bf6-f276-be296c47143c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GELU prediction    RMSE=3.1800 MSE=10.1124 MAE=2.3185 R2=-0.0363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Residual Block prediction"
      ],
      "metadata": {
        "id": "yzkLJTOARndK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, dim, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim, dim),\n",
        "        )\n",
        "        self.ln = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.ln(x + self.block(x))\n",
        "\n",
        "class ResidualPredictionModel(nn.Module):\n",
        "    def __init__(self, in_dim, mae):\n",
        "        super().__init__()\n",
        "        self.mae = mae\n",
        "\n",
        "        for param in self.mae.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.input_proj = nn.Sequential(\n",
        "            nn.LayerNorm(in_dim),\n",
        "            nn.Linear(in_dim, 256),\n",
        "            nn.SiLU()\n",
        "        )\n",
        "\n",
        "        self.residual_blocks = nn.Sequential(\n",
        "            ResidualBlock(256, dropout=0.3),\n",
        "            ResidualBlock(256, dropout=0.2)\n",
        "        )\n",
        "\n",
        "        self.output_head = nn.Sequential(\n",
        "            nn.Linear(256, 128),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc = self.mae.encoder(x)  # (B, D)\n",
        "        x = self.input_proj(enc)   # (B, 256)\n",
        "        x = self.residual_blocks(x)\n",
        "        return self.output_head(x)\n",
        "\n",
        "torch.manual_seed(42); torch.cuda.manual_seed_all(42)\n",
        "pred_model = ResidualPredictionModel(in_dim=128, mae=model).cuda()\n",
        "pred_model.input_proj.apply(initialize_weights)\n",
        "pred_model.output_head.apply(initialize_weights)\n",
        "pred_model.residual_blocks.apply(initialize_weights)\n",
        "_ = train(pred_model, train_loader, n_epochs=20, lr=1e-4)"
      ],
      "metadata": {
        "id": "JitilkfrRpfu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "025caa63-2b30-42ca-d1de-73c606f15bd1"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss = 39.6192  R2 = 0.7852\n",
            "Epoch 2: loss = 7.2985  R2 = 0.9604\n",
            "Epoch 3: loss = 6.4085  R2 = 0.9653\n",
            "Epoch 4: loss = 5.9576  R2 = 0.9677\n",
            "Epoch 5: loss = 5.6980  R2 = 0.9691\n",
            "Epoch 6: loss = 5.5381  R2 = 0.9700\n",
            "Epoch 7: loss = 5.3896  R2 = 0.9708\n",
            "Epoch 8: loss = 5.2798  R2 = 0.9714\n",
            "Epoch 9: loss = 5.1755  R2 = 0.9720\n",
            "Epoch 10: loss = 5.1079  R2 = 0.9723\n",
            "Epoch 11: loss = 5.0338  R2 = 0.9727\n",
            "Epoch 12: loss = 4.9863  R2 = 0.9730\n",
            "Epoch 13: loss = 4.9003  R2 = 0.9734\n",
            "Epoch 14: loss = 4.8753  R2 = 0.9736\n",
            "Epoch 15: loss = 4.8479  R2 = 0.9737\n",
            "Epoch 16: loss = 4.7913  R2 = 0.9740\n",
            "Epoch 17: loss = 4.7931  R2 = 0.9740\n",
            "Epoch 18: loss = 4.7590  R2 = 0.9742\n",
            "Epoch 19: loss = 4.7634  R2 = 0.9742\n",
            "Epoch 20: loss = 4.7702  R2 = 0.9742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = evaluate(\"Residual prediction\", pred_model, test_loader)"
      ],
      "metadata": {
        "id": "9tnpHZEAR6g9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ce1c5a9-1b47-4085-dd1e-01cf78f08615"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Residual prediction RMSE=2.5244 MSE=6.3724 MAE=2.0607 R2=0.3470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42); torch.cuda.manual_seed_all(42)\n",
        "pred_model = ResidualPredictionModel(in_dim=128, mae=model).cuda()\n",
        "pred_model.input_proj.apply(initialize_weights)\n",
        "pred_model.output_head.apply(initialize_weights)\n",
        "pred_model.residual_blocks.apply(initialize_weights)\n",
        "_ = train(pred_model, train_loader, n_epochs=50, lr=1e-4)\n",
        "_ = evaluate(\"Residual prediction\", pred_model, test_loader)"
      ],
      "metadata": {
        "id": "LJ1tKmvhR84a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb6a7ba1-503a-4851-c042-b7d45a2b92b9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss = 39.6192  R2 = 0.7852\n",
            "Epoch 2: loss = 7.2962  R2 = 0.9605\n",
            "Epoch 3: loss = 6.4029  R2 = 0.9653\n",
            "Epoch 4: loss = 5.9476  R2 = 0.9678\n",
            "Epoch 5: loss = 5.6837  R2 = 0.9692\n",
            "Epoch 6: loss = 5.5210  R2 = 0.9701\n",
            "Epoch 7: loss = 5.3646  R2 = 0.9709\n",
            "Epoch 8: loss = 5.2566  R2 = 0.9715\n",
            "Epoch 9: loss = 5.1408  R2 = 0.9721\n",
            "Epoch 10: loss = 5.0510  R2 = 0.9726\n",
            "Epoch 11: loss = 4.9626  R2 = 0.9731\n",
            "Epoch 12: loss = 4.9056  R2 = 0.9734\n",
            "Epoch 13: loss = 4.8054  R2 = 0.9740\n",
            "Epoch 14: loss = 4.7683  R2 = 0.9742\n",
            "Epoch 15: loss = 4.7088  R2 = 0.9745\n",
            "Epoch 16: loss = 4.6245  R2 = 0.9749\n",
            "Epoch 17: loss = 4.6099  R2 = 0.9750\n",
            "Epoch 18: loss = 4.5394  R2 = 0.9754\n",
            "Epoch 19: loss = 4.5141  R2 = 0.9755\n",
            "Epoch 20: loss = 4.4966  R2 = 0.9756\n",
            "Epoch 21: loss = 4.4476  R2 = 0.9759\n",
            "Epoch 22: loss = 4.3945  R2 = 0.9762\n",
            "Epoch 23: loss = 4.3817  R2 = 0.9763\n",
            "Epoch 24: loss = 4.3543  R2 = 0.9764\n",
            "Epoch 25: loss = 4.3112  R2 = 0.9766\n",
            "Epoch 26: loss = 4.3084  R2 = 0.9767\n",
            "Epoch 27: loss = 4.2662  R2 = 0.9769\n",
            "Epoch 28: loss = 4.2306  R2 = 0.9771\n",
            "Epoch 29: loss = 4.2214  R2 = 0.9771\n",
            "Epoch 30: loss = 4.2108  R2 = 0.9772\n",
            "Epoch 31: loss = 4.2207  R2 = 0.9771\n",
            "Epoch 32: loss = 4.1738  R2 = 0.9774\n",
            "Epoch 33: loss = 4.1651  R2 = 0.9774\n",
            "Epoch 34: loss = 4.1335  R2 = 0.9776\n",
            "Epoch 35: loss = 4.1381  R2 = 0.9776\n",
            "Epoch 36: loss = 4.1204  R2 = 0.9777\n",
            "Epoch 37: loss = 4.1007  R2 = 0.9778\n",
            "Epoch 38: loss = 4.1087  R2 = 0.9777\n",
            "Epoch 39: loss = 4.0947  R2 = 0.9778\n",
            "Epoch 40: loss = 4.0735  R2 = 0.9779\n",
            "Epoch 41: loss = 4.0992  R2 = 0.9778\n",
            "Epoch 42: loss = 4.0709  R2 = 0.9779\n",
            "Epoch 43: loss = 4.0770  R2 = 0.9779\n",
            "Epoch 44: loss = 4.0536  R2 = 0.9780\n",
            "Epoch 45: loss = 4.0527  R2 = 0.9780\n",
            "Epoch 46: loss = 4.0464  R2 = 0.9781\n",
            "Epoch 47: loss = 4.0570  R2 = 0.9780\n",
            "Epoch 48: loss = 4.0690  R2 = 0.9779\n",
            "Epoch 49: loss = 4.0884  R2 = 0.9778\n",
            "Epoch 50: loss = 4.0493  R2 = 0.9781\n",
            "Residual prediction RMSE=2.5933 MSE=6.7252 MAE=2.1214 R2=0.3108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tq2LAuZ9aQcT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}